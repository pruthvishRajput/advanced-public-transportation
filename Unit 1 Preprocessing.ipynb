{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store raw location records into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import and initialize MongoClient'''\n",
    "from pymongo import MongoClient\n",
    "con = MongoClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with storing the raw location records (available in `.txt`) from bus module into MongoDB database. By \"raw\" location records we mean the location records are as they were stored in Bus Module android application and we have not applied preprocessing to it. Three versions of Bus module application were used for recording location traces with minor changes. In the first version `RawRecords`, the `time` was recorded in <tt>'dd Month YYYY hh mm ss'</tt>  string format (for eg: *8 Jan 2018 07:41:43*). Whereas in the second version `RawRecordEpoch`, the time was recorded in the epoch format. and in the third version `RawRecordEpochSpeed`, the additional parameter `GPS Speed` was recorded. The raw location records correspoding to each version are stored separately in the folder corresponding to version name.\n",
    "\n",
    "The function `ReadLocationRecordsAndSeparateIntoSegement` reads the raw location records and separates the raw location records into different trip records, if the time between two consecutive records is greater than 30 min. \n",
    "\n",
    "Subsequently, it saves the separated trips records into MongoDB with `dd_mm_yyyy__hh_mm_ss.RawRecords` as a collection name. Here <tt>dd_mm_yyyy__hh_mm_ss</tt> represents the start time of the trip and <tt>RawRecords</tt> indicates that the given collection is of raw location record. \n",
    "\n",
    "Futher, a status information related to every trip is maintained after every operation in `TripInfo` Collection. This is used at every stages to extract relevant record at each stage of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RouteName='Git_ISCON_PDPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one have executed the current notebook and have created MongoDB database previously then the following code needs to be executed for creating the fresh MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn the same way remove the Processed location record with GPS speed\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Used for deleting the database from MongoDB for clearing the MongoDB database, \n",
    "in case one have created the database earlier by executing the below codes.'''\n",
    "#con.drop_database(RouteName)\n",
    "\n",
    "'''\n",
    "In the same way remove the Processed location record with GPS speed\n",
    "'''\n",
    "#path = \"/\".join(os.getcwd().split('/')) + \"/LocationRecords/RawRecordEpochSpeedProcessed\"\n",
    "#for file in [f for f in os.listdir(path)]:\n",
    "#    os.remove(path+\"/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/\".join(os.getcwd().split('/')) +'/Codes/LibCodes')\n",
    "\n",
    "'''Import project specific library'''\n",
    "import ReadSeparateTripMongo\n",
    "\n",
    "path = \"/\".join(os.getcwd().split('/')) + \"/LocationRecords\"\n",
    "\n",
    "'''Read location records folders'''\n",
    "BusModuleVersion = [f for f in os.listdir(path) if '.md' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport importlib\\nimportlib.reload(ReadSeparateTripMongo)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''For updating the lib changes effects'''\n",
    "'''\n",
    "import importlib\n",
    "importlib.reload(ReadSeparateTripMongo)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ISCON_PDPU+1?29_01_2018_16_03_04.txt\n",
      "Reading file: ISCON_PDPU+1?07_02_2018_09_29_00\n",
      "Reading file: ISCON_PDPU+1?18_01_2018_07_38_10\n",
      "Reading file: ISCON_PDPU+1?22_12_2017_07_38_21\n",
      "Reading file: ISCON_PDPU+1?19_12_2017_18_41_16\n",
      "Reading file: ISCON_PDPU+1?08_01_2018_07_41_43\n",
      "Reading file: ISCON_PDPU+1?27_12_2017_07_55_49\n",
      "Reading file: ISCON_PDPU+1?12_02_2018_08_47_22.txt\n",
      "Reading file: ISCON_PDPU+1?15_02_2018_16_08_07.txt\n",
      "Reading file: ISCON_PDPU+1?21_02_2018_16_49_58.txt\n",
      "Reading file: ISCON_PDPU+1?23_03_2018_08_47_23\n",
      "Reading file: ISCON_PDPU+1?02_04_18_01_51_00\n",
      "Reading file: ISCON_PDPU+1?23_03_2018_08_47_22\n",
      "Reading file: ISCON_PDPU+1?14_02_2018_12_39_44.txt\n",
      "Reading file: ISCON_PDPU+1?22_02_2018_12_06_55.txt\n",
      "Reading file: ISCON_PDPU+1?12_02_2018_08_47_22.txt\n",
      "Reading file: ISCON_PDPU+1?15_02_2018_16_08_07.txt\n",
      "Reading file: ISCON_PDPU+1?21_02_2018_16_49_58.txt\n",
      "Reading file: ISCON_PDPU+1?23_03_2018_08_47_23\n",
      "Reading file: ISCON_PDPU+1?02_04_18_01_51_00\n",
      "Reading file: ISCON_PDPU+1?23_03_2018_08_47_22\n",
      "Reading file: ISCON_PDPU+1?14_02_2018_12_39_44.txt\n",
      "Reading file: ISCON_PDPU+1?22_02_2018_12_06_55.txt\n"
     ]
    }
   ],
   "source": [
    "'''Read location records and separate them into trips. Subsequently store them into MongoDB'''\n",
    "for RecordType in BusModuleVersion:\n",
    "    LocationRecordDir = '/'.join([path, RecordType])\n",
    "    for fileName in [f for f in os.listdir(LocationRecordDir)]:\n",
    "        \n",
    "        if RecordType == 'RawRecordEpochSpeed':\n",
    "            \n",
    "            ReadSeparateTripMongo.HandlerForNALocation(fileName, \n",
    "                                                       LocationRecordDir, \n",
    "                                                       LocationRecordDir + 'Processed')\n",
    "            \n",
    "            ReadSeparateTripMongo.ReadLocationRecordsAndSeparateIntoSegement(RouteName,\n",
    "                                                                             fileName,\n",
    "                                                                             LocationRecordDir + 'Processed',\n",
    "                                                                             RecordType)\n",
    "\n",
    "        else:\n",
    "            ReadSeparateTripMongo.ReadLocationRecordsAndSeparateIntoSegement(RouteName,\n",
    "                                                                             fileName,\n",
    "                                                                             LocationRecordDir,\n",
    "                                                                             RecordType)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `ReadSeparateTripMongo.HandlerForNALocation` and `ReadSeparateTripMongo.ReadLocationRecordsAndSeparateIntoSegement` are the project specific library function. One can find help related to project specific functions by executing `FunctionName?`. For instance, on executing the below cell, the help window related to function will pop-up. For further reference, one can also look the library code file in the LibCode directory as mentioned in the file field on executing the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadSeparateTripMongo.ReadLocationRecordsAndSeparateIntoSegement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MongoDB Collection record and it's representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the `Trip` collection record for one of the trip (let say trip: *29_12_2017__07_37_27*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5d8b4ac252d4e734fb7eb1f2'),\n",
       "  'SingleTripInfo': '29_12_2017__07_37_27',\n",
       "  'filteredLocationRecord': False,\n",
       "  'DBSCANOp': False,\n",
       "  'segments': -1,\n",
       "  'segmentsTimeStamp': []}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rec for rec in con[RouteName]['TripInfo'].find({'SingleTripInfo':'29_12_2017__07_37_27'})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the keys represents the status of the operations applied on the location records. For instance key `filteredLocationRecord` represents whether the given location records are filtered or not, `DBSCANOp` represents whether the DBSCAN based stoppage detection algorithm is applied on the collection records or not, `Segment` represents the number of segments in the location record, after applying interpolation and segmentation procedure. Concretely, the procedure segments the location record if it founds the GPS outage in the location record (the procedure is described later subsection). Likewise, `segmentsTimeStamp` determines the time stamp corresponding to segments in the location records in order to avoid GPS outage from consideration, in all the subsequent procedures. Further, at different stages of modules, the status are computed for all the trips in order to keep the track of operation applied to a given trip. Subsequently, the modules extracts the location record by querying the MongoDB collection *TripInfo* with the *status flag* values. For instance, in order to extract the trips on which filtering is not applied we would query MongoDB as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleTripsInfo = [rec['SingleTripInfo'] for rec in con[RouteName]['TripInfo'].find({'filteredLocationRecord': False})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29_01_2018__07_39_47', '30_01_2018__07_42_30', '01_02_2018__07_39_12', '02_02_2018__07_38_50', '18_01_2018__07_38_10', '19_01_2018__07_38_47', '22_01_2018__07_41_04', '22_12_2017__07_38_21', '22_12_2017__18_38_34', '26_12_2017__07_32_35', '19_12_2017__18_41_16', '20_12_2017__07_38_14', '20_12_2017__18_31_19', '21_12_2017__07_52_59', '08_01_2018__07_41_43', '08_01_2018__18_37_49', '09_01_2018__07_40_01', '27_12_2017__07_55_48', '29_12_2017__07_37_27', '01_01_2018__07_38_27', '12_02_2018__07_40_14', '14_02_2018__18_30_22', '15_02_2018__07_45_52', '15_02_2018__16_08_22', '15_02_2018__18_33_19', '16_02_2018__07_45_41', '19_02_2018__07_46_19', '20_02_2018__07_41_48', '20_02_2018__18_31_07', '21_02_2018__07_42_42', '13_03_2018__07_29_52', '14_03_2018__07_35_46', '20_03_2018__07_28_45', '28_03_2018__18_39_21', '21_03_2018__07_32_39', '21_03_2018__18_32_40', '22_03_2018__07_38_43', '14_02_2018__07_41_04', '21_02_2018__18_28_29', '22_02_2018__07_42_45', '12_02_2018__07_40_14', '14_02_2018__18_30_22', '15_02_2018__07_45_52', '15_02_2018__16_08_22', '15_02_2018__18_33_19', '16_02_2018__07_45_41', '19_02_2018__07_46_19', '20_02_2018__07_41_48', '20_02_2018__18_31_07', '21_02_2018__07_42_42', '13_03_2018__07_29_52', '14_03_2018__07_35_46', '20_03_2018__07_28_45', '28_03_2018__18_39_21', '21_03_2018__07_32_39', '21_03_2018__18_32_40', '22_03_2018__07_38_43', '14_02_2018__07_41_04', '21_02_2018__18_28_29', '22_02_2018__07_42_45']\n"
     ]
    }
   ],
   "source": [
    "print(SingleTripsInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the fields of collection record for a raw location record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5d8b4abb52d4e734fb7e53b4'),\n",
       "  'epoch': 1517191787000.0,\n",
       "  'Longitude': 72.508215,\n",
       "  'Latitude': 23.03014,\n",
       "  'Accuracy': 6.599999904632568}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rec for rec in con[RouteName][SingleTripsInfo[0]+'.RawRecords'].find().limit(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,\n",
    "`_id` is the unique object id assigned by MongoDB, `Longitude`, `Latitude` corresponds to the location attributes and \n",
    "`Accuracy` is the accuracy of location record in meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location records are now stored in MongoDB collections, let us know look at the filtering preprocessing steps. \n",
    "\n",
    "### Outlier removal\n",
    "A given location record is considered as an outlier and reomved if\n",
    "\n",
    "$$ ac > \\bar{ac} + 3 \\times \\sigma_{ac}$$\n",
    "where $\\bar{ac}$ and $\\sigma_{ac}$ is the mean and deviation of accuracy considering all the location records of a trip, respectively.\n",
    "\n",
    "### Segmentation and interpolation\n",
    "If the consecutive location records are separated by lesser duration ($<15$ seconds) or lesser distance ($<50$ m) then apply interpolation. Else, we separate the location records into different segment and update the information related to segment into the trip status information record of *TripInfo* collection.\n",
    "\n",
    "Note that we extracted the trips for which filtering is not done using the code \n",
    "\n",
    "```python\n",
    "SingleTripsInfo = [rec['SingleTripInfo'] for rec in con[RouteName]['TripInfo'].find({'filteredLocationRecord': False})]\n",
    "```\n",
    "\n",
    "Now, we shall appy filtering into these *SingleTripsInfo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For updating the lib changes effects'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''For updating the lib changes effects'''\n",
    "#importlib.reload(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing filtering on 29_01_2018__07_39_47\n",
      "Executing filtering on 30_01_2018__07_42_30\n",
      "Executing filtering on 01_02_2018__07_39_12\n",
      "Executing filtering on 02_02_2018__07_38_50\n",
      "Executing filtering on 18_01_2018__07_38_10\n",
      "Executing filtering on 19_01_2018__07_38_47\n",
      "Executing filtering on 22_01_2018__07_41_04\n",
      "Executing filtering on 22_12_2017__07_38_21\n",
      "Executing filtering on 22_12_2017__18_38_34\n",
      "Executing filtering on 26_12_2017__07_32_35\n",
      "Executing filtering on 19_12_2017__18_41_16\n",
      "Executing filtering on 20_12_2017__07_38_14\n",
      "Executing filtering on 20_12_2017__18_31_19\n",
      "Executing filtering on 21_12_2017__07_52_59\n",
      "Executing filtering on 08_01_2018__07_41_43\n",
      "Executing filtering on 08_01_2018__18_37_49\n",
      "Executing filtering on 09_01_2018__07_40_01\n",
      "Executing filtering on 27_12_2017__07_55_48\n",
      "Executing filtering on 29_12_2017__07_37_27\n",
      "Executing filtering on 01_01_2018__07_38_27\n",
      "Executing filtering on 12_02_2018__07_40_14\n",
      "Executing filtering on 14_02_2018__18_30_22\n",
      "Executing filtering on 15_02_2018__07_45_52\n",
      "Executing filtering on 15_02_2018__16_08_22\n",
      "Executing filtering on 15_02_2018__18_33_19\n",
      "Executing filtering on 16_02_2018__07_45_41\n",
      "Executing filtering on 19_02_2018__07_46_19\n",
      "Executing filtering on 20_02_2018__07_41_48\n",
      "Executing filtering on 20_02_2018__18_31_07\n",
      "Executing filtering on 21_02_2018__07_42_42\n",
      "Executing filtering on 13_03_2018__07_29_52\n",
      "Executing filtering on 14_03_2018__07_35_46\n",
      "Executing filtering on 20_03_2018__07_28_45\n",
      "Executing filtering on 28_03_2018__18_39_21\n",
      "Executing filtering on 21_03_2018__07_32_39\n",
      "Executing filtering on 21_03_2018__18_32_40\n",
      "Executing filtering on 22_03_2018__07_38_43\n",
      "Executing filtering on 14_02_2018__07_41_04\n",
      "Executing filtering on 21_02_2018__18_28_29\n",
      "Executing filtering on 22_02_2018__07_42_45\n",
      "Executing filtering on 12_02_2018__07_40_14\n",
      "Executing filtering on 14_02_2018__18_30_22\n",
      "Executing filtering on 15_02_2018__07_45_52\n",
      "Executing filtering on 15_02_2018__16_08_22\n",
      "Executing filtering on 15_02_2018__18_33_19\n",
      "Executing filtering on 16_02_2018__07_45_41\n",
      "Executing filtering on 19_02_2018__07_46_19\n",
      "Executing filtering on 20_02_2018__07_41_48\n",
      "Executing filtering on 20_02_2018__18_31_07\n",
      "Executing filtering on 21_02_2018__07_42_42\n",
      "Executing filtering on 13_03_2018__07_29_52\n",
      "Executing filtering on 14_03_2018__07_35_46\n",
      "Executing filtering on 20_03_2018__07_28_45\n",
      "Executing filtering on 28_03_2018__18_39_21\n",
      "Executing filtering on 21_03_2018__07_32_39\n",
      "Executing filtering on 21_03_2018__18_32_40\n",
      "Executing filtering on 22_03_2018__07_38_43\n",
      "Executing filtering on 14_02_2018__07_41_04\n",
      "Executing filtering on 21_02_2018__18_28_29\n",
      "Executing filtering on 22_02_2018__07_42_45\n"
     ]
    }
   ],
   "source": [
    "for SingleTripInfo in SingleTripsInfo:\n",
    "    Preprocessing.ApplyFiltering(RouteName,SingleTripInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside applying the filtering procedure, the `Preprocessing.ApplyFiltering` computes the relative std deviation of the location records in a trip. It also computes the starting hour of the trip. Further, it updates the segmentation information, mean accuracy, std deviation in the accuracy of the location records, trip starting hour in the collection record of a trip in the *TripInfo* collection. For instance, let us now look at the Trip collection record for one of the trip (let say trip: 29_12_2017__07_37_27) as we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5d8b4ac252d4e734fb7eb1f2'),\n",
       "  'SingleTripInfo': '29_12_2017__07_37_27',\n",
       "  'filteredLocationRecord': True,\n",
       "  'DBSCANOp': False,\n",
       "  'segments': 3,\n",
       "  'segmentsTimeStamp': [[1514513259000.0, 1514513272000.0],\n",
       "   [1514513291000.0, 1514516035000.0],\n",
       "   [1514516089000.0, 1514516189000.0]],\n",
       "  'RelativeSTDAccuracy': 11.342842637811202,\n",
       "  'TripStartHour': '07',\n",
       "  'meanAccuracy': 4.157360201823962,\n",
       "  'stdAccuracy': 0.4715628255798822}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rec for rec in con[RouteName]['TripInfo'].find({'SingleTripInfo':'29_12_2017__07_37_27'})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may change the trip (i.e. *29_12_2017__07_37_27*) and replace it with any of the other trips of the `SingleTripsInfo` for displaying the corresponding status of the selected trip. \n",
    "\n",
    "We would like to draw the attention of readers to the fields of the *TripInfo* collection record. The `Preprocessing.ApplyFiltering` have updated the field `filteredLocationRecord` to **True**, as it has applied the filtering process on a trip. Like wise, the other fields have also updated with the computed values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
